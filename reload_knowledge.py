import os
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

def reload_knowledge_base():
    """–ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
    embeddings = HuggingFaceEmbeddings(
        model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2',
        model_kwargs={'device': 'cpu'}
    )
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    
    all_docs = []
    
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –≤ –ø–∞–ø–∫–µ data
    for filename in os.listdir('data'):
        if filename.endswith('.txt'):
            filepath = os.path.join('data', filename)
            try:
                loader = TextLoader(filepath, encoding='utf-8')
                documents = loader.load()
                doc_splits = text_splitter.split_documents(documents)
                all_docs.extend(doc_splits)
                print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω: {filename}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤ {filename}: {e}")
    
    # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É
    vector_db = Chroma.from_documents(
        documents=all_docs,
        embedding=embeddings,
        persist_directory="chroma_db"
    )
    vector_db.persist()
    
    print(f"üéâ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_docs)}")

if __name__ == "__main__":
    reload_knowledge_base()
